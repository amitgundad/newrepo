{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movie Recommendation System with BigData.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPFbTIgEF0etmoSWrW4UgZg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitgundad/pySpark/blob/master/Movie_Recommendation_System_with_BigData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZsbARhr46o4"
      },
      "source": [
        "The goal of this smaple is to extract insights from a large dataset with the help of Big Data frameworks (Spark, Hadoop) and machine learning techniques (e.g. classification, collaborative filtering, clustering, frequent pattern mining)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf5pNsnI54R2"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# install spark (change the version number if needed)\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "\n",
        "# unzip the spark file to the current folder\n",
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz\n",
        "\n",
        "# set your spark folder to your system path environment. \n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "# install findspark using pip\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4cAdii16TLL",
        "outputId": "7907dde4-9147-417c-d0de-9865865db118"
      },
      "source": [
        "# Findspark for Jupyter Notebook (spark-2.4.4-bin-hadoop2.7)\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "# Start Apache Spark Session & Context\n",
        "import pyspark\n",
        "from pyspark.sql import SQLContext\n",
        "\n",
        "sc = pyspark.SparkContext(appName='sd701-RecoSys-Models')\n",
        "sqlContext = SQLContext(sc)\n",
        "\n",
        "print('Master : ', sc.master)\n",
        "print('Cores  : ', sc.defaultParallelism)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Master :  local[*]\n",
            "Cores  :  2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm_iPASW6cA8"
      },
      "source": [
        "sqlContext.sparkSession.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNlaBanj7Dh_",
        "outputId": "b100e339-0575-4f69-e4c1-4089d965de7c"
      },
      "source": [
        "!pip install koalas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting koalas\n",
            "  Downloading koalas-1.8.2-py3-none-any.whl (390 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 23.6 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 30 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 40 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 81 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 317 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 327 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 337 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 348 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 358 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 368 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 378 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 389 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 390 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=0.10 in /usr/local/lib/python3.7/dist-packages (from koalas) (3.0.0)\n",
            "Requirement already satisfied: pandas>=0.23.2 in /usr/local/lib/python3.7/dist-packages (from koalas) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from koalas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.2->koalas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.2->koalas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.2->koalas) (1.15.0)\n",
            "Installing collected packages: koalas\n",
            "Successfully installed koalas-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rgzb9PQA7IcZ",
        "outputId": "66fddc86-6178-4169-ca64-56df4977b962"
      },
      "source": [
        "# Default Packages (available by Default in Google Colab)\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns\n",
        "import random\n",
        "from pprint import pprint\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "# Downloaded Packages (not available by Default)\n",
        "import databricks.koalas\n",
        "\n",
        "# PySpark Utilities\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.ml.recommendation import ALS, ALSModel\n",
        "from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
        "from pyspark.mllib.evaluation import RegressionMetrics, RankingMetrics\n",
        "\n",
        "# Random Seed\n",
        "SEED = 1492\n",
        "\n",
        "# Set-up\n",
        "plt.style.use('seaborn')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. Koalas will set it for you but it does not work if there is a Spark context already launched.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVAA_NJC7SUl",
        "outputId": "3a64d43a-a1b0-471f-8108-b59f4f3bb990"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8devojj7YWA",
        "outputId": "8ad5fb79-6604-40bb-9827-e47e033fd621"
      },
      "source": [
        "!ls \"drive/My Drive/Big Data Analytics/Sample Program\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ml-25m\tml-25m.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feQz-T1-7mfg"
      },
      "source": [
        "DATA_PATH = \"drive/My Drive/Big Data Analytics/Sample Program/ml-25m\"\n",
        "RESULTS_PATH = \"drive/My Drive/Big Data Analytics/Sample Program/Results\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIDIJfRe-Kqc"
      },
      "source": [
        "class MovieLensDatasets(object):\n",
        "\n",
        "  def __init__(self, ratings, movies, links, personalRatings, debug=True, debugLimit=10000):\n",
        "  # Load Existing Data\n",
        "    if debug:\n",
        "      debugLimit = debugLimit\n",
        "      ratings = ratings.limit(debugLimit)\n",
        "    else:\n",
        "      ratings = ratings      \n",
        "\n",
        "    self.ratings = ratings\n",
        "    self.movies = movies\n",
        "    self.links = links\n",
        "    self.personalRatings = personalRatings\n",
        "\n",
        "    # Create New DataFrame\n",
        "    users = ratings.select('userId').distinct()\n",
        "    self.users = users\n",
        "\n",
        "  def preprocessing(self):\n",
        "    # Preprocess MovieLens Ratings\n",
        "    self.ratings = self.ratings.withColumn('rating',\n",
        "      F.col('rating').cast('double')).drop('timestamp') \\\n",
        "      .withColumn('userId', F.col('userId').cast('int')) \\\n",
        "      .withColumn('movieId', F.col('movieId').cast('int'))\n",
        "\n",
        "    # Preprocess Personal IMDb Ratings To MovieLens Ratings\n",
        "    self.personalRatings = self.personalRatings.select(['Const',\n",
        "                                                    'Your Rating']) \\\n",
        "          .withColumnRenamed('Const', 'imdbId') \\\n",
        "          .withColumnRenamed('Your Rating', 'personalRating')\n",
        "\n",
        "    self.personalRatings = self.personalRatings \\\n",
        "        .withColumn('personalRating', F.col('personalRating').cast('double')*0.5) \\\n",
        "        .withColumn('imdbId', F.expr(\"substr(imdbId, 3)\"))\n",
        "\n",
        "    self.personalRatings = self.personalRatings.join(\n",
        "        self.links.select('movieId', 'imdbId'), ['imdbId'], how='inner')\n",
        "\n",
        "    # Insert IMDb Ratings into MovieLens Ratings Dataset\n",
        "    self.personalRatings = self.personalRatings \\\n",
        "                        .withColumn('userId', F.lit('0'))\n",
        "    self.personalRatings = self.personalRatings \\\n",
        "                        .select(['userId', 'movieId', 'personalRating']) \\\n",
        "                        .toDF('userId', 'movieId', 'rating')\n",
        "    self.ratings = self.ratings.union(self.personalRatings)\n",
        "\n",
        "    # Binarize MovieLens Ratings (if rating >= 3.0, then 1.0, else 0.0)\n",
        "    udf_scale_ratings = F.udf(lambda x: x - 2.5, DoubleType())\n",
        "    udf_binary_ratings = F.udf(lambda x: 1.0 if x > 0.0 else 0.0, DoubleType())\n",
        "\n",
        "    self.ratings = self.ratings \\\n",
        "    .withColumn('ratingsScaled', udf_scale_ratings(F.col('rating'))) \\\n",
        "    .withColumn('ratingsBinary', udf_binary_ratings(F.col('ratingsScaled')))\n",
        "\n",
        "    def get_ratings(self):\n",
        "        return self.ratings\n",
        "\n",
        "    def get_movies(self):\n",
        "        return self.movies\n",
        "\n",
        "    # Displaying Null Values\n",
        "    def spark_df_display_null_values(sparkDf):\n",
        "        print('NaN values ?')\n",
        "        sparkDf.select([F.count(F.when(F.isnan(c), c)).alias(c) for c in sparkDf.columns]).show()\n",
        "\n",
        "        print('Null values ?')\n",
        "        sparkDf.select([F.count(F.when(F.isnull(c), c)).alias(c) for c in sparkDf.columns]).show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTCeX5cf-RCE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}